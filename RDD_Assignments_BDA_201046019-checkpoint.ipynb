{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast\n",
    "spark = SparkSession.builder.appName(\"Test RDD Examples\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.session.SparkSession"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create RDDs in three different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDDs\n",
    "# Using parallelize method\n",
    "rdd_par = spark.sparkContext.parallelize([\"Hello World\", \"Hope you are not fed up with ABD class\", \"ello\"])\n",
    "type(rdd_par)\n",
    "rdd_par.collect()\n",
    "rdd_par.count()\n",
    "rdd_par.collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World', 'Hope you are not fed up with ABD class']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDD using transformations\n",
    "rdd_trans = rdd_par.filter(lambda word:word.startswith('H'))\n",
    "rdd_trans.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is perhaps the best known database to be found in the pattern recognition literature. Fisher's paper is a classic in the field and is referenced frequently to this day. \",\n",
       " '(See Duda & Hart, for example.) ',\n",
       " 'The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. One class is linearly separable from the other 2; the latter are NOT linearly separable from each other.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating RDD using Data Sources\n",
    "rdd_ds = spark.sparkContext.textFile('input.txt')\n",
    "rdd_ds.count()\n",
    "rdd_ds.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read a text file and count number of words in the file using RDD operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the file: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_ds = spark.sparkContext.textFile('input.txt')\n",
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "print(\"Number of words in the file: \")\n",
    "word_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a program to find the word frequency in a given file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('is', 4),\n",
       " ('perhaps', 1),\n",
       " ('best', 1),\n",
       " ('known', 1),\n",
       " ('database', 1),\n",
       " ('in', 2),\n",
       " ('pattern', 1),\n",
       " (\"Fisher's\", 1),\n",
       " ('field', 1),\n",
       " ('referenced', 1),\n",
       " ('this', 1),\n",
       " ('', 2),\n",
       " ('Hart,', 1),\n",
       " ('example.)', 1),\n",
       " ('The', 1),\n",
       " ('set', 1),\n",
       " ('of', 2),\n",
       " ('50', 1),\n",
       " ('instances', 1),\n",
       " ('each,', 1),\n",
       " ('where', 1),\n",
       " ('class', 2),\n",
       " ('refers', 1),\n",
       " ('type', 1),\n",
       " ('plant.', 1),\n",
       " ('One', 1),\n",
       " ('linearly', 2),\n",
       " ('other', 1),\n",
       " ('2;', 1),\n",
       " ('latter', 1),\n",
       " ('are', 1),\n",
       " ('This', 1),\n",
       " ('the', 5),\n",
       " ('to', 3),\n",
       " ('be', 1),\n",
       " ('found', 1),\n",
       " ('recognition', 1),\n",
       " ('literature.', 1),\n",
       " ('paper', 1),\n",
       " ('a', 2),\n",
       " ('classic', 1),\n",
       " ('and', 1),\n",
       " ('frequently', 1),\n",
       " ('day.', 1),\n",
       " ('(See', 1),\n",
       " ('Duda', 1),\n",
       " ('&', 1),\n",
       " ('for', 1),\n",
       " ('data', 1),\n",
       " ('contains', 1),\n",
       " ('3', 1),\n",
       " ('classes', 1),\n",
       " ('each', 2),\n",
       " ('iris', 1),\n",
       " ('separable', 2),\n",
       " ('from', 2),\n",
       " ('NOT', 1),\n",
       " ('other.', 1)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "freq_words = word_rdd.map(lambda word: (word, 1))\n",
    "freq_words.reduceByKey(lambda a, b: a + b).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a program to convert all words in a file to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"THIS IS PERHAPS THE BEST KNOWN DATABASE TO BE FOUND IN THE PATTERN RECOGNITION LITERATURE. FISHER'S PAPER IS A CLASSIC IN THE FIELD AND IS REFERENCED FREQUENTLY TO THIS DAY. \",\n",
       " '(SEE DUDA & HART, FOR EXAMPLE.) ',\n",
       " 'THE DATA SET CONTAINS 3 CLASSES OF 50 INSTANCES EACH, WHERE EACH CLASS REFERS TO A TYPE OF IRIS PLANT. ONE CLASS IS LINEARLY SEPARABLE FROM THE OTHER 2; THE LATTER ARE NOT LINEARLY SEPARABLE FROM EACH OTHER.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_upper = rdd_ds.map(lambda word: word.upper())\n",
    "word_rdd_upper.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to convert all words in a file to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"this is perhaps the best known database to be found in the pattern recognition literature. fisher's paper is a classic in the field and is referenced frequently to this day. \",\n",
       " '(see duda & hart, for example.) ',\n",
       " 'the data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant. one class is linearly separable from the other 2; the latter are not linearly separable from each other.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_lower = rdd_ds.map(lambda word: word.lower())\n",
    "word_rdd_lower.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a program to capitalize first leter of each words in file (use string capitalize() method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This Is Perhaps The Best Known Database To Be Found In The Pattern Recognition Literature. Fisher's Paper Is A Classic In The Field And Is Referenced Frequently To This Day. \",\n",
       " '(see Duda & Hart, For Example.) ',\n",
       " 'The Data Set Contains 3 Classes Of 50 Instances Each, Where Each Class Refers To A Type Of Iris Plant. One Class Is Linearly Separable From The Other 2; The Latter Are Not Linearly Separable From Each Other.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_capitalized = rdd_ds.map(lambda word: [w.capitalize() for w in word.split(' ')]  )\n",
    "word_rdd_capitalized = word_rdd_capitalized.map(lambda word: ' '.join(word)  )\n",
    "word_rdd_capitalized.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Find the longest length of word from given set of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest word length is: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd_longest = rdd_ds.flatMap(lambda word: word.split(' '))\n",
    "word_rdd_longest = word_rdd_longest.map(lambda word: len(word))\n",
    "print(\"The longest word length is: \")\n",
    "word_rdd_longest.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Map the Registration numbers to corresponding branch. 6000 series BDA, 9000 series HDA, 1000 series ML, 2000 series VLSI, 3000 series ES, 4000 series MSc, 5000 series CC. Given registration number, generate a key-value pair of Registration Number and Corresponding Branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key, value are: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(6002, 'BDA'), (3050, 'ES'), (2500, 'VLSI'), (1500, 'ML'), (9050, 'HDA')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = [6002, 3050, 2500, 1500, 9050]\n",
    "rdd_par = spark.sparkContext.parallelize(series)\n",
    "rdd_sequence = rdd_par.map(lambda series: (series, 'ML') if (series >= 1000 and series < 1999)  \n",
    "                           else ((series, 'VLSI') if (series >= 2000 and series < 2999)\n",
    "                           else ((series, 'ES') if (series >= 3000 and series < 3999) \n",
    "                           else ((series, 'MSc') if (series >= 4000 and series < 4999) \n",
    "                           else ((series, 'CC') if (series >= 5000 and series < 5999) \n",
    "                           else ((series, 'BDA') if (series >= 6000 and series < 6999)\n",
    "                           else ((series, 'HDA') if (series >= 9000 and series < 9999) else (series, 'NA'))))))))\n",
    "\n",
    "print(\"Key, value are: \")\n",
    "rdd_sequence.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Text file contain numbers. Numbers are separated by one white space. There is no order to store the numbers. One line may contain one or more numbers. Find the maximum, minimum, sum and mean of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum:  456\n",
      "The minimum:  10\n",
      "The minimum:  936\n",
      "The minimum:  72.0\n"
     ]
    }
   ],
   "source": [
    "rdd_ds = spark.sparkContext.textFile('numbers.txt')\n",
    "rdd_ds_num = rdd_ds.flatMap(lambda n: n.split(' '))\n",
    "rdd_ds_num = rdd_ds_num.map(lambda n: int(n))\n",
    "print(\"The maximum: \", rdd_ds_num.max())\n",
    "print(\"The minimum: \", rdd_ds_num.min())\n",
    "print(\"The minimum: \", rdd_ds_num.sum())\n",
    "print(\"The minimum: \", rdd_ds_num.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. A text file (citizen.txt) contains data about citizens of country. Fields (information in file) are Name, dob, Phone, email and state name. Another file contains mapping of state names to state code like Karnataka is codes as KA, TamilNadu as TN, Kerala KL etc. Compress the citizen.txt file by changing full state name to state code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('K', ('u', 'a')), ('K', ('u', 'e'))]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_ds_citizen = spark.sparkContext.textFile('citizen.txt')\n",
    "rdd_ds_statecode = spark.sparkContext.textFile('statecode.txt')\n",
    "rdd_ds_citizen = rdd_ds_citizen.map(lambda citizen: citizen.split(' '))\n",
    "rdd_ds_statecode = rdd_ds_statecode.map(lambda state: state.split(' '))\n",
    "#rdd_ds_citizen.join(rdd_ds_statecode).collect()\n",
    "#rdd_ds_citizen.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
